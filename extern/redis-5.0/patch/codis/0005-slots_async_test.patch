diff --git a/extern/redis-5.0/src/Makefile b/extern/redis-5.0/src/Makefile
index 149c8f2e..c72476e6 100644
--- a/extern/redis-5.0/src/Makefile
+++ b/extern/redis-5.0/src/Makefile
@@ -273,6 +273,9 @@ test: $(REDIS_SERVER_NAME) $(REDIS_CHECK_AOF_NAME)
 test-sentinel: $(REDIS_SENTINEL_NAME)
 	@(cd ..; ./runtest-sentinel)
 
+test-codis: $(REDIS_SERVER_NAME) $(REDIS_SENTINEL_NAME)
+	@(cd ..; ./runtest-codis)
+
 check: test
 
 lcov:
diff --git a/extern/redis-5.0/tests/codis/codis.tcl b/extern/redis-5.0/tests/codis/codis.tcl
index f7dd3805..02a3be93 100644
--- a/extern/redis-5.0/tests/codis/codis.tcl
+++ b/extern/redis-5.0/tests/codis/codis.tcl
@@ -4,6 +4,25 @@
 # This software is released under the BSD License. See the COPYING file for
 # more information.
 
+proc get_key_type_size {id key} {
+    set type [R $id type $key]
+    if {[string compare $type "list"] == 0} {
+        set tmp [R $id llen $key]
+    } elseif {[string compare $type "hash"] == 0} {
+        set tmp [R $id hlen $key]
+    } elseif {[string compare $type "zset"] == 0} {
+        set tmp [R $id zcard $key]
+    } elseif {[string compare $type "set"] == 0} {
+        set tmp [R $id scard $key]
+    } else {
+        puts "unsupported type: $type"
+        assert {1 == 0}
+    }
+    set size [lindex $tmp 0]
+    set res [list $type $size]
+    return $res
+}
+
 proc get_key_slot {id key} {
     set res [R $id slotshashkey $key]
     return [lindex $res 0]
@@ -19,59 +38,305 @@ proc get_slot_size {id slot} {
     return $slot_size
 }
 
-proc creat_some_keys {id prefix type {num 1} {start 0}} {
+proc pick_slot_key {id slot} {
+    set res [R $id slotsscan $slot 0]
+    set keys [lindex $res 1]
+    return [lindex $keys 0]
+}
+
+proc generate_hset_args {x y batch} {
+    set args {}
+    for {set i 0} {$i < $batch} {incr i} {
+        lappend args "f_$x" $y
+        incr x
+        incr y
+    }
+    return $args
+}
+
+proc generate_zadd_args {x y batch} {
+    set args {}
+    for {set i 0} {$i < $batch} {incr i} {
+        lappend args $y "e_$x"
+        incr x
+        incr y
+    }
+    return $args
+}
+
+proc generate_sadd_args {x y batch} {
+    set args {}
+    for {set i 0} {$i < $batch} {incr i} {
+        lappend args "e_$y"
+        incr y
+    }
+    return $args
+}
+
+proc create_complex_keys {id prefix type size {num 1} {start 0} {batch 1}} {
     set max_idx [expr {$start + $num}]
     for {set j $start} {$j < $max_idx} {incr j} {
         set key "$prefix:$j"
-        if {[string compare $type "hash"] == 0} {
-            R $id hset $key a $j b [expr $j+1] c [expr $j+2]
-        } elseif {[string compare $type "zset"] == 0} {
-            R $id zadd $key $j a [expr $j+1] b [expr $j+2] c
-        } elseif {[string compare $type "set"] == 0} {
-            R $id sadd $key a $j b [expr $j+1] c [expr $j+2]
-        } elseif {[string compare $type "list"] == 0} {
-            R $id lpush $key a $j b [expr $j+1] c [expr $j+2]
-        } else {
-            puts "unknown type: $type"
-            assert {1 == 0}
+        for {set x 0} {$x < $size} {incr x $batch} {
+            set y [expr {$j + $x}]
+            if {[string compare $type "hash"] == 0} {
+                set args [generate_hset_args $x $y $batch]
+                R $id hset $key {*}$args
+            } elseif {[string compare $type "zset"] == 0} {
+                set args [generate_zadd_args $x $y $batch]
+                R $id zadd $key {*}$args
+            } elseif {[string compare $type "set"] == 0} {
+                set args [generate_sadd_args $x $y $batch]
+                R $id sadd $key {*}$args
+            } elseif {[string compare $type "list"] == 0} {
+                set args [generate_sadd_args $x $y $batch]
+                R $id lpush $key {*}$args
+            } else {
+                puts "unsupported type: $type"
+                assert {1 == 0}
+            }
         }
     }
     return $max_idx
 }
 
-proc sync_migrate_key {src dst key {tag 1}} {
-    set dst_host [get_instance_attrib redis $dst host]
-    set dst_port [get_instance_attrib redis $dst port]
+proc create_some_pairs {id prefix cnt1 cnt2 small large} {
+    # generate some string type k-v pairs by $prefix
+    R $id DEBUG populate $cnt1 $prefix
+
+    # generate some complex type k-v pairs by $prefix
+    set batch 100;  # how many new elements will be generated in each round
+    set start $cnt1
+    set start [create_complex_keys $id $prefix "hash" $small $cnt2 $start]
+    set start [create_complex_keys $id $prefix "hash" $large $cnt2 $start $batch]
+    set start [create_complex_keys $id $prefix "zset" $small $cnt2 $start]
+    set start [create_complex_keys $id $prefix "zset" $large $cnt2 $start $batch]
+    set start [create_complex_keys $id $prefix "set" $small $cnt2 $start]
+    set start [create_complex_keys $id $prefix "set" $large $cnt2 $start $batch]
+    set start [create_complex_keys $id $prefix "list" $small $cnt2 $start]
+    set total [create_complex_keys $id $prefix "list" $large $cnt2 $start $batch]
+    return $total
+}
+
+proc sync_migrate_key {src dst tag key} {
+    # init the parameters for the migration
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGONE
+    } else {
+        set cmd SLOTSMGRTONE
+    }
     set timeout 10;  # seconds
-    if {$tag == 0} {
-        set res [R $src SLOTSMGRTONE $dst_host $dst_port $timeout $key]
+
+    # do the migration
+    set res [R $src $cmd $dhost $dport $timeout $key]
+    return $res
+}
+
+proc sync_migrate_slot {src dst tag slot {print 0}} {
+    # init the parameters for the migration
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGSLOT
     } else {
-        set res [R $src SLOTSMGRTTAGONE $dst_host $dst_port $timeout $key]
+        set cmd SLOTSMGRTSLOT
+    }
+    set timeout 10;  # seconds
+
+    # circularly migrate the keys of the slot from $src to $dst
+    set round 0
+    set total 0
+    while 1 {
+        incr round
+        set res [R $src $cmd $dhost $dport $timeout $slot]
+        set succ [lindex $res 0]
+        set size [lindex $res 1]
+        if {$print == 1} {
+            puts "Round $round: size=$size,succ=$succ"
+        }
+        incr total $succ
+        if {$size == 0} break
     }
+    set res [list $round $total]
     return $res
 }
 
-proc sync_migrate_slot {src dst slot {tag 1}} {
+proc async_migrate_key {src dst tag bulks bytes args} {
     # init the parameters for the migration
-    set dst_host [get_instance_attrib redis $dst host]
-    set dst_port [get_instance_attrib redis $dst port]
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGONE-ASYNC
+    } else {
+        set cmd SLOTSMGRTONE-ASYNC
+    }
     set timeout 10;  # seconds
-    if {$tag == 0} {
-        set cmd SLOTSMGRTSLOT
+
+    # do the migration
+    set res [R $src $cmd $dhost $dport $timeout $bulks $bytes {*}$args]
+    return $res
+}
+
+proc async_migrate_slot {src dst tag bulks bytes slot num {print 0}} {
+    # init the parameters for the migration
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGSLOT-ASYNC
     } else {
-        set cmd SLOTSMGRTTAGSLOT
+        set cmd SLOTSMGRTSLOT-ASYNC
     }
+    set timeout 10;  # seconds
 
-    # circularly migrate the slot from $src to $dst
+    # circularly migrate the keys of the slot from $src to $dst
     set round 0
-    set succ 0
+    set total 0
     while 1 {
         incr round
-        set res [R $src $cmd $dst_host $dst_port $timeout $slot]
-        incr succ [lindex $res 0]
+        set res [R $src $cmd $dhost $dport $timeout $bulks $bytes $slot $num]
+        set succ [lindex $res 0]
         set size [lindex $res 1]
+        if {$print == 1} {
+            puts "Round $round: size=$size,succ=$succ"
+        }
+        incr total $succ
         if {$size == 0} break
     }
-    set res [list $round $succ]
+    set res [list $round $total]
     return $res
 }
+
+proc handle_async_migrate_done {link type reply} {
+    puts "AsyncMigrate finished: $type '$reply'"
+}
+
+proc trigger_async_migrate_key {src dst tag bulks bytes args} {
+    # create a new client for async migration
+    set shost [get_instance_attrib redis $src host]
+    set sport [get_instance_attrib redis $src port]
+    set link [redis $shost $sport]
+    $link blocking 0;  # use non-blocking mode
+
+    # init the parameters for the migration
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGONE-ASYNC
+    } else {
+        set cmd SLOTSMGRTONE-ASYNC
+    }
+    set timeout 10;  # seconds
+
+    # trigger the migration
+    set callback [list handle_async_migrate_done]
+    $link $cmd $dhost $dport $timeout $bulks $bytes {*}$args $callback
+    puts "AsyncMigrate key([lindex $args 0]){#$src => #$dst} starting..."
+}
+
+proc trigger_async_migrate_slot {src dst tag bulks bytes slot num} {
+    # create a new client for async migration
+    set shost [get_instance_attrib redis $src host]
+    set sport [get_instance_attrib redis $src port]
+    set link [redis $shost $sport]
+    $link blocking 0;  # use non-blocking mode
+
+    # init the parameters for the migration
+    set dhost [get_instance_attrib redis $dst host]
+    set dport [get_instance_attrib redis $dst port]
+    if {$tag == 1} {
+        set cmd SLOTSMGRTTAGSLOT-ASYNC
+    } else {
+        set cmd SLOTSMGRTSLOT-ASYNC
+    }
+    set timeout 10;  # seconds
+
+    # trigger the migration
+    set callback [list handle_async_migrate_done]
+    $link $cmd $dhost $dport $timeout $bulks $bytes $slot $num $callback
+    puts "AsyncMigrate slot_$slot{#$src => #$dst} starting..."
+}
+
+proc migrate_exec_wrapper {id key args} {
+    catch {R $id SLOTSMGRT-EXEC-WRAPPER $key {*}$args} e
+    return $e
+}
+
+proc get_migration_status {id} {
+    puts [R $id SLOTSMGRT-ASYNC-STATUS]
+}
+
+proc test_async_migration_with_invalid_params {src key tag args} {
+    if {$key == 1} {
+        if {$tag == 1} {
+            set cmd SLOTSMGRTTAGONE-ASYNC
+        } else {
+            set cmd SLOTSMGRTONE-ASYNC
+        }
+    } else {
+        if {$tag == 1} {
+            set cmd SLOTSMGRTTAGSLOT-ASYNC
+        } else {
+            set cmd SLOTSMGRTSLOT-ASYNC
+        }
+    }
+    # set the normal value of the migration parameters
+    set dhost "127.0.0.1"
+    set dport 10000
+    set timeout 10
+    set maxbulks 200
+    set maxbytes 1024000
+    # set the value over range
+    set bigv1 65536;       # USHRT_MAX+1
+    set bigv2 2147483648;  # INT_MAX+1
+
+    # check invalid dst port
+    catch {R $src $cmd $dhost 0 $timeout $maxbulks $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*port*} $e
+    catch {R $src $cmd $dhost $bigv1 $timeout $maxbulks $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*port*} $e
+    puts ">>> ($cmd) Checking of invalid port value: PASS"
+
+    # check invalid timeout
+    catch {R $src $cmd $dhost $dport -1 $maxbulks $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*timeout*} $e
+    catch {R $src $cmd $dhost $dport $bigv2 $maxbulks $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*timeout*} $e
+    puts ">>> ($cmd) Checking of invalid timeout value: PASS"
+
+    # check invalid maxbulks
+    catch {R $src $cmd $dhost $dport $timeout -1 $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*maxbulks*} $e
+    catch {R $src $cmd $dhost $dport $timeout $bigv2 $maxbytes {*}$args} e
+    assert_match {*ERR*invalid*maxbulks*} $e
+    puts ">>> ($cmd) Checking of invalid maxbulks value: PASS"
+
+    # check invalid maxbytes
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks -1 {*}$args} e
+    assert_match {*ERR*invalid*maxbytes*} $e
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks $bigv2 {*}$args} e
+    assert_match {*ERR*invalid*maxbytes*} $e
+    puts ">>> ($cmd) Checking of invalid maxbytes value: PASS"
+
+    if {$key == 1} {
+        return $cmd
+    }
+    set slot [lindex $args 0]
+    set num [lindex $args 1]
+
+    # check invalid slotId
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks $maxbytes -1 $num} e
+    assert_match {*ERR*invalid*slot*} $e
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks $maxbytes 1024 $num} e
+    assert_match {*ERR*invalid*slot*} $e
+    puts ">>> ($cmd) Checking of invalid slotId value: PASS"
+
+    # check invalid numkeys
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks $maxbytes $slot -1} e
+    assert_match {*ERR*invalid*numkeys*} $e
+    catch {R $src $cmd $dhost $dport $timeout $maxbulks $maxbytes $slot $bigv2} e
+    assert_match {*ERR*invalid*numkeys*} $e
+    puts ">>> ($cmd) Checking of invalid numkeys value: PASS"
+    return $cmd
+}
diff --git a/extern/redis-5.0/tests/codis/run.tcl b/extern/redis-5.0/tests/codis/run.tcl
index 9e4741be..b0eb10bb 100644
--- a/extern/redis-5.0/tests/codis/run.tcl
+++ b/extern/redis-5.0/tests/codis/run.tcl
@@ -9,9 +9,11 @@ source ../instances.tcl
 set ::master_base_port 30000;
 set ::replica_base_port 40000;
 set ::group_count 3;  # How many groups(master + replica) we use at max.
+set ::sentinel_count 3;  # How many sentinels we use at max.
 
 proc main {} {
     parse_options
+    spawn_instance sentinel $::sentinel_base_port $::sentinel_count 0
     spawn_instance redis $::master_base_port $::group_count 0
     spawn_instance redis $::replica_base_port $::group_count $::group_count {
         "appendonly yes"
diff --git a/extern/redis-5.0/tests/codis/tests/01-sync-migration.tcl b/extern/redis-5.0/tests/codis/tests/01-sync-migration.tcl
index 8b56474b..f823bc0f 100644
--- a/extern/redis-5.0/tests/codis/tests/01-sync-migration.tcl
+++ b/extern/redis-5.0/tests/codis/tests/01-sync-migration.tcl
@@ -14,19 +14,19 @@ test "Migrate one untagged key by sync method" {
     R $src sadd stest a b c d
     set dig_src [R $src debug digest]
     assert_equal OK [R $src slotscheck]
-    puts ">>> Init the enviroment: PASS"
+    puts ">>> Init the enviroment: OK"
 
     # select the command for migration
     set tag 0;  # 0 means SLOTSMGRTONE, while 1 means SLOTSMGRTTAGONE
 
     # check the migration of a non-existent key
-    assert_equal 0 [sync_migrate_key $src $dst "none" $tag]
+    assert_equal 0 [sync_migrate_key $src $dst $tag "none"]
     puts ">>> Migrate a non-existent key: PASS"
 
     # check the migration of a string type key
     set dig_vals [R $src debug digest-value "test:0" "test:1"]
-    assert_equal 1 [sync_migrate_key $src $dst "test:0" $tag]
-    assert_equal 1 [sync_migrate_key $src $dst "test:1" $tag]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "test:0"]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "test:1"]
     assert_equal $dig_vals [R $dst debug digest-value "test:0" "test:1"]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -34,7 +34,7 @@ test "Migrate one untagged key by sync method" {
 
     # check the migration of a list type key
     set dig_val [R $src debug digest-value "ltest"]
-    assert_equal 1 [sync_migrate_key $src $dst "ltest" $tag]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "ltest"]
     assert_equal $dig_val [R $dst debug digest-value "ltest"]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -42,7 +42,7 @@ test "Migrate one untagged key by sync method" {
 
     # check the migration of a hash type key
     set dig_val [R $src debug digest-value "htest"]
-    assert_equal 1 [sync_migrate_key $src $dst "htest" $tag]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "htest"]
     assert_equal $dig_val [R $dst debug digest-value "htest"]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -50,7 +50,7 @@ test "Migrate one untagged key by sync method" {
 
     # check the migration of a zset type key
     set dig_val [R $src debug digest-value "ztest"]
-    assert_equal 1 [sync_migrate_key $src $dst "ztest" $tag]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "ztest"]
     assert_equal $dig_val [R $dst debug digest-value "ztest"]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -58,14 +58,15 @@ test "Migrate one untagged key by sync method" {
 
     # check the migration of a set type key
     set dig_val [R $src debug digest-value "stest"]
-    assert_equal 1 [sync_migrate_key $src $dst "stest" $tag]
+    assert_equal 1 [sync_migrate_key $src $dst $tag "stest"]
     assert_equal $dig_val [R $dst debug digest-value "stest"]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
-    puts ">>> Migrate a set type key: PASS"
+    puts ">>> Migrate a set  type key: PASS"
 
     # verify the data isn't corrupted or changed after migration
     assert_equal $dig_src [R $dst debug digest]
+    puts ">>> Verify the data after migration: PASS"
     puts -nonewline ">>> End of the case: "
 }
 
@@ -77,20 +78,21 @@ test "Migrate one tagged key by sync method" {
     set prefix "{test}"
     set count [randomInt 10]; incr count;  # avoid the bad case: count == 0
     R $src debug populate $count $prefix
-    set total $count
-    set total [creat_some_keys $src $prefix "hash" $count $total]
-    set total [creat_some_keys $src $prefix "zset" $count $total]
-    set total [creat_some_keys $src $prefix "set" $count $total]
-    set total [creat_some_keys $src $prefix "list" $count $total]
+    set ksize 5;  # size of the complex key
+    set start $count
+    set start [create_complex_keys $src $prefix "hash" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "zset" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "set" $ksize $count $start]
+    set total [create_complex_keys $src $prefix "list" $ksize $count $start]
     set dig_src [R $src debug digest]
     assert_equal OK [R $src slotscheck]
-    puts ">>> Init the enviroment(count=$count,total=$total): PASS"
+    puts ">>> Init the enviroment(count=$count,total=$total): OK"
 
     # select the command for migration
     set tag 1;  # 0 means SLOTSMGRTONE, while 1 means SLOTSMGRTTAGONE
 
     # check the migration of a non-existent tagged key
-    assert_equal 0 [sync_migrate_key $src $dst "{none}" $tag]
+    assert_equal 0 [sync_migrate_key $src $dst $tag "{none}"]
     puts ">>> Migrate a non-existent key: PASS"
 
     # check the migration of a randomly picked tagged key
@@ -98,7 +100,7 @@ test "Migrate one tagged key by sync method" {
     set key "$prefix:$rand"
     set type [R $src type $key]
     set dig_val [R $src debug digest-value $key]
-    assert_equal $total [sync_migrate_key $src $dst $key $tag]
+    assert_equal $total [sync_migrate_key $src $dst $tag $key]
     assert_equal $dig_val [R $dst debug digest-value $key]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -109,7 +111,7 @@ test "Migrate one tagged key by sync method" {
     set key "$prefix:$j"
     set type [R $dst type $key]
     set dig_val [R $dst debug digest-value $key]
-    assert_equal $total [sync_migrate_key $dst $src $key $tag]
+    assert_equal $total [sync_migrate_key $dst $src $tag $key]
     assert_equal $dig_val [R $src debug digest-value $key]
     assert_equal OK [R $src slotscheck]
     assert_equal OK [R $dst slotscheck]
@@ -117,6 +119,7 @@ test "Migrate one tagged key by sync method" {
 
     # verify the data isn't corrupted or changed after migration
     assert_equal $dig_src [R $src debug digest]
+    puts ">>> Verify the data after migration: PASS"
     puts -nonewline ">>> End of the case: "
 }
 
@@ -129,20 +132,22 @@ test "Migrate one static slot(no writing) by sync method" {
     set rand [randomInt 102400]
     set prefix "{test_$rand}"
     set slot [get_key_slot $src $prefix]
-    creat_some_keys $src $prefix "hash" 10 0
-    creat_some_keys $src $prefix "zset" 10 10
-    creat_some_keys $src $prefix "set" 10 20
-    creat_some_keys $src $prefix "list" 10 30
+    set ksize 5;  # size of the complex key
+    set count 5;  # number of the keys in each type
+    set start 0
+    set start [create_complex_keys $src $prefix "hash" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "zset" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "set" $ksize $count $start]
+    set total [create_complex_keys $src $prefix "list" $ksize $count $start]
     assert_equal OK [R $src slotscheck]
-    puts ">>> Init the enviroment(slot=$slot,prefix=$prefix): PASS"
-
     # record the digest and slot size brfore migration
     set dig_src [R $src debug digest]
     set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size,prefix=$prefix): OK"
 
     # migrate the slot from $src to $dst by SLOTSMGRTSLOT
-    set tag 0
-    set res [sync_migrate_slot $src $dst $slot $tag]
+    set tag 0;  # 0 means SLOTSMGRTSLOT, while 1 means SLOTSMGRTTAGSLOT
+    set res [sync_migrate_slot $src $dst $tag $slot]
     set round1 [lindex $res 0]
     assert_equal $bak_size [lindex $res 1];    # succ == original slot size
     set dst_size [get_slot_size $dst $slot]
@@ -153,8 +158,8 @@ test "Migrate one static slot(no writing) by sync method" {
     puts ">>> Migrate slot_$slot{#$src => #$dst} by SLOTSMGRTSLOT: PASS"
 
     # migrate the slot from $dst to $src by SLOTSMGRTTAGSLOT
-    set tag 1
-    set res [sync_migrate_slot $dst $src $slot $tag]
+    set tag 1;  # 0 means SLOTSMGRTSLOT, while 1 means SLOTSMGRTTAGSLOT
+    set res [sync_migrate_slot $dst $src $tag $slot]
     assert {[lindex $res 0] < $round1};        # *TAG* cmd should be faster
     assert_equal $bak_size [lindex $res 1];    # succ == original slot size
     set src_size [get_slot_size $src $slot];
@@ -166,5 +171,6 @@ test "Migrate one static slot(no writing) by sync method" {
 
     # verify the data isn't corrupted or changed after 2 migrations
     assert_equal $dig_src [R $src debug digest]
+    puts ">>> Verify the data after migration: PASS"
     puts -nonewline ">>> End of the case: "
 }
diff --git a/extern/redis-5.0/tests/codis/tests/02-async-migration-key.tcl b/extern/redis-5.0/tests/codis/tests/02-async-migration-key.tcl
new file mode 100644
index 00000000..c4d1551f
--- /dev/null
+++ b/extern/redis-5.0/tests/codis/tests/02-async-migration-key.tcl
@@ -0,0 +1,198 @@
+# Codis async migration test for a single key.
+
+source "../tests/includes/init-tests.tcl"
+
+test "Migrate a single key by async method with invalid parameters" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Init the enviroment: OK"
+
+    set key 1;  # 1 means migrate key, while 0 means migrate slot
+    set tag 0;  # 1 means use the cmd with TAG, while 0 means not
+    set cmd [test_async_migration_with_invalid_params $src $key $tag "none"]
+    puts ">>> Checking of $cmd completed."
+    set tag 1
+    set cmd [test_async_migration_with_invalid_params $src $key $tag "{none}"]
+    puts ">>> Checking of $cmd completed."
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate one untagged key by async method in PAYLOAD encoding" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    R $src debug populate 2 "test"
+    R $src lpush ltest a b c d
+    R $src hset htest f1 v1 f2 v2 f3 v3
+    R $src zadd ztest 0 a 1 b 2 c 3 d
+    R $src sadd stest a b c d
+    set dig_src [R $src debug digest]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Init the enviroment: OK"
+
+    # set the parameters of the migration
+    set tag 0;  # 0 means SLOTSMGRTONE-ASYNC, while 1 means SLOTSMGRTTAGONE-ASYNC
+    set maxbulks 200;      # should be much larger than the key size
+    set maxbytes 1048576;  # 1MB
+
+    # check the migration of a non-existent key
+    assert_equal 0 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "none"]
+    puts ">>> Migrate a non-existent key: PASS"
+
+    # check the migration of a string type key
+    set dig_vals [R $src debug digest-value "test:0" "test:1"]
+    assert_equal 2 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "test:0" "test:1"]
+    assert_equal $dig_vals [R $dst debug digest-value "test:0" "test:1"]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a string type key: PASS"
+
+    # check the migration of a list type key
+    set dig_val [R $src debug digest-value "ltest"]
+    assert_equal 1 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "ltest"]
+    assert_equal $dig_val [R $dst debug digest-value "ltest"]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a list type key: PASS"
+
+    # check the migration of a hash type key
+    set dig_val [R $src debug digest-value "htest"]
+    assert_equal 1 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "htest"]
+    assert_equal $dig_val [R $dst debug digest-value "htest"]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a hash type key: PASS"
+
+    # check the migration of a zset type key
+    set dig_val [R $src debug digest-value "ztest"]
+    assert_equal 1 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "ztest"]
+    assert_equal $dig_val [R $dst debug digest-value "ztest"]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a zset type key: PASS"
+
+    # check the migration of a set type key
+    set dig_val [R $src debug digest-value "stest"]
+    assert_equal 1 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "stest"]
+    assert_equal $dig_val [R $dst debug digest-value "stest"]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a set  type key: PASS"
+
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $dig_src [R $dst debug digest]
+    puts ">>> Verify the data after migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate one tagged key by async method in PAYLOAD encoding" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    set prefix "{test}"
+    set count [randomInt 10]; incr count;  # avoid the bad case: count == 0
+    R $src debug populate $count $prefix
+    set ksize 5;  # size of the complex key
+    set start $count
+    set start [create_complex_keys $src $prefix "hash" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "zset" $ksize $count $start]
+    set start [create_complex_keys $src $prefix "set" $ksize $count $start]
+    set total [create_complex_keys $src $prefix "list" $ksize $count $start]
+    set dig_src [R $src debug digest]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Init the enviroment(count=$count,total=$total): OK"
+
+    # set the parameters of the migration
+    set tag 1;  # 0 means SLOTSMGRTONE-ASYNC, while 1 means SLOTSMGRTTAGONE-ASYNC
+    set maxbulks 200;      # should be much larger than the key size($ksize)
+    set maxbytes 1048576;  # 1MB
+
+    # check the migration of a non-existent tagged key
+    assert_equal 0 [async_migrate_key $src $dst $tag $maxbulks $maxbytes "{none}"]
+    puts ">>> Migrate a non-existent key: PASS"
+
+    # check the migration of a randomly picked tagged key
+    set rand [randomInt $total]
+    set key "$prefix:$rand"
+    set type [R $src type $key]
+    set dig_val [R $src debug digest-value $key]
+    assert_equal $total [async_migrate_key $src $dst $tag $maxbulks $maxbytes $key]
+    assert_equal $dig_val [R $dst debug digest-value $key]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a tagged key($type, $key){#$src => #$dst}: PASS"
+
+    # check the migration of another tagged key with different type
+    set j [expr {($rand + $count) % $total}]
+    set key "$prefix:$j"
+    set type [R $dst type $key]
+    set dig_val [R $dst debug digest-value $key]
+    assert_equal $total [async_migrate_key $dst $src $tag $maxbulks $maxbytes $key]
+    assert_equal $dig_val [R $src debug digest-value $key]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a tagged key($type, $key){#$dst => #$src}: PASS"
+
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $dig_src [R $src debug digest]
+    puts ">>> Verify the data after migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
+
+proc test_bigkey_async_migration {type} {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    set ksize 100000
+    create_complex_keys $src "{test}" $type $ksize 1 0 100
+    assert_equal OK [R $src slotscheck]
+    set key "{test}:0"
+    set dig_val [R $src debug digest-value $key]
+    set desc [get_key_type_size $src $key]
+    puts ">>> Init the enviroment($desc): OK"
+
+    # set the parameters of the migration
+    set maxbulks 200;      # should be much smaller than the key size($ksize)
+    set maxbytes 1048576;  # 1MB
+
+    # migrate the bigkey by SLOTSMGRTONE-ASYNC
+    set tag 0;  # 0 means SLOTSMGRTONE-ASYNC, while 1 means SLOTSMGRTTAGONE-ASYNC
+    assert_equal 1 [async_migrate_key $src $dst $tag $maxbulks $maxbytes $key]
+    assert_equal $dig_val [R $dst debug digest-value $key]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a big $type key{#$src => #$dst}: PASS"
+
+    # migrate the bigkey by SLOTSMGRTTAGONE-ASYNC
+    set tag 1;  # 0 means SLOTSMGRTONE-ASYNC, while 1 means SLOTSMGRTTAGONE-ASYNC
+    assert_equal 1 [async_migrate_key $dst $src $tag $maxbulks $maxbytes $key]
+    assert_equal $dig_val [R $src debug digest-value $key]
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate a big $type key{#$dst => #$src}: PASS"
+}
+
+test "Migrate a list type bigkey by async method in CHUNKED encoding" {
+    test_bigkey_async_migration "list"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate a hash type bigkey by async method in CHUNKED encoding" {
+    test_bigkey_async_migration "hash"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate a zset type bigkey by async method in CHUNKED encoding" {
+    test_bigkey_async_migration "zset"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate a set type bigkey by async method in CHUNKED encoding" {
+    test_bigkey_async_migration "set"
+    puts -nonewline ">>> End of the case: "
+}
diff --git a/extern/redis-5.0/tests/codis/tests/03-async-migration-slot.tcl b/extern/redis-5.0/tests/codis/tests/03-async-migration-slot.tcl
new file mode 100644
index 00000000..9910436c
--- /dev/null
+++ b/extern/redis-5.0/tests/codis/tests/03-async-migration-slot.tcl
@@ -0,0 +1,77 @@
+# Codis async migration test for a hash slot.
+
+source "../tests/includes/init-tests.tcl"
+
+test "Migrate a hash slot by async method with invalid parameters" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Init the enviroment: OK"
+
+    set key 0;  # 1 means migrate key, while 0 means migrate slot
+    set slot 256
+    set num 200
+    set tag 0;  # 1 means use the cmd with TAG, while 0 means not
+    set cmd [test_async_migration_with_invalid_params $src $key $tag $slot $num]
+    puts ">>> Checking of $cmd completed."
+    set tag 1
+    set cmd [test_async_migration_with_invalid_params $src $key $tag $slot $num]
+    puts ">>> Checking of $cmd completed."
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Migrate one static slot(no writing) by async method" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    R $src debug populate 102400;  # almost 100 keys in each slot
+    set rand [randomInt 102400]
+    set prefix "{test_$rand}"
+    set slot [get_key_slot $src $prefix]
+    set small 20;   # size of the small complex key
+    set large 500;  # size of the large complex key
+    set cnt 5;      # number of the keys in each type
+    set total [create_some_pairs $src $prefix $cnt $cnt $small $large]
+    assert_equal OK [R $src slotscheck]
+    # record the digest and slot size brfore migration
+    set dig_src [R $src debug digest]
+    set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size,prefix=$prefix): OK"
+
+    # set the parameters of the migration
+    set maxbulks 200;      # $small < $maxbulks < $large
+    set maxbytes 1048576;  # 1MB
+    set numkeys 30;        # should be much smaller than the slot size
+    set print 1;           # if print the detail in each round or not
+
+    # migrate the slot from $src to $dst by SLOTSMGRTSLOT-ASYNC
+    set tag 0;  # 0 => SLOTSMGRTSLOT-ASYNC, 1 => SLOTSMGRTTAGSLOT-ASYNC
+    set res [async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys $print]
+    set round1 [lindex $res 0]
+    assert_equal $bak_size [lindex $res 1];    # succ == original slot size
+    set dst_size [get_slot_size $dst $slot]
+    assert_equal $bak_size $dst_size;          # all the keys have been moved
+    assert_equal 0 [get_slot_size $src $slot]; # nothing has been left on $src
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate slot_$slot{#$src => #$dst} by SLOTSMGRTSLOT-ASYNC: PASS"
+
+    # migrate the slot from $dst to $src by SLOTSMGRTTAGSLOT-ASYNC
+    set tag 1;  # 0 => SLOTSMGRTSLOT-ASYNC, 1 => SLOTSMGRTTAGSLOT-ASYNC
+    set res [async_migrate_slot $dst $src $tag $maxbulks $maxbytes $slot $numkeys $print]
+    assert {[lindex $res 0] < $round1};        # *TAG* cmd should be faster
+    assert_equal $bak_size [lindex $res 1];    # succ == original slot size
+    set src_size [get_slot_size $src $slot];
+    assert_equal $bak_size $src_size;          # all the keys have been moved
+    assert_equal 0 [get_slot_size $dst $slot]; # nothing has been left on $dst
+    assert_equal OK [R $src slotscheck]
+    assert_equal OK [R $dst slotscheck]
+    puts ">>> Migrate slot_$slot{#$dst => #$src} by SLOTSMGRTTAGSLOT-ASYNC: PASS"
+
+    # verify the data isn't corrupted or changed after 2 migrations
+    assert_equal $dig_src [R $src debug digest]
+    puts ">>> Verify the data after migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
diff --git a/extern/redis-5.0/tests/codis/tests/04-slotsmgrt-exec-wrapper.tcl b/extern/redis-5.0/tests/codis/tests/04-slotsmgrt-exec-wrapper.tcl
new file mode 100644
index 00000000..a5c483d7
--- /dev/null
+++ b/extern/redis-5.0/tests/codis/tests/04-slotsmgrt-exec-wrapper.tcl
@@ -0,0 +1,207 @@
+# Codis test for reading && writing when migrating.
+
+source "../tests/includes/init-tests.tcl"
+
+test "Read&&Write a key by wrapper combine with key async migrating" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    set slot 1
+    set strcnt 100;    # count of the string type keys
+    set cpxcnt 1;      # count of each complex type keys
+    set small 20;      # size of the small complex key
+    set large 100000;  # size of the large complex key
+    set prefix1 "{2J8mrF}";  # can be hashed to slot1
+    set total1 [create_some_pairs $src $prefix1 $strcnt $cpxcnt $small $large]
+    set prefix2 "{key:65}";  # can be hashed to slot1
+    set total2 [create_some_pairs $src $prefix2 $strcnt $cpxcnt $small $large]
+    assert_equal OK [R $src slotscheck]
+    # record the digest and slot size brfore migration
+    set dig_src [R $src debug digest]
+    set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size): OK"
+
+    # random pick 2 keys, k2 will be migrated after k1 has been done
+    set rand [expr {$total1 - ([randomInt 4] * 2 + 1)}]
+    set k1 "$prefix1:$rand"
+    set t1 [lindex [get_key_type_size $src $k1] 0]
+    set rand [expr {$total2 - ([randomInt 4] * 2 + 1)}]
+    set k2 "$prefix2:$rand"
+    set t2 [lindex [get_key_type_size $src $k2] 0]
+
+    # read/write the key by wrapper with invalid parameters
+    set res [migrate_exec_wrapper $src $k1]
+    assert_match {*ERR*wrong*number*arguments*} $res
+    set res [migrate_exec_wrapper $src $k1 JOKE $k1]
+    assert_match {*ERR*invalid*command*} $res
+    set res [migrate_exec_wrapper $src $k1 TYPE $k1 $k2]
+    assert_match {*ERR*wrong*number*arguments*} $res
+    puts ">>> R&&W k1($t1, $k1) by wrapper with invalid parameters: PASS"
+
+    # trigger the async migration of k1
+    set tag 1;  # 0 => SLOTSMGRTONE-ASYNC, 1 => SLOTSMGRTTAGONE-ASYNC
+    set maxbulks 200;     # $small < $maxbulks < $large
+    set maxbytes 51200;   # 50KB(a small value, make the migration to be slower)
+    trigger_async_migrate_key $src $dst $tag $maxbulks $maxbytes $k1
+
+    # read/write k1 by wrapper when migrating k1
+    set res [migrate_exec_wrapper $src $k1 TYPE $k1]
+    assert_equal 2 [lindex $res 0]
+    assert_equal $t1 [lindex $res 1]
+    set res [migrate_exec_wrapper $src $k1 EXPIRE $k1 600]
+    assert_match {*ERR*being*migrated*} $res
+    puts ">>> R&&W k1($t1, $k1) by wrapper when migrating k1: PASS"
+
+    # read/write k2 by wrapper when migrating k1
+    set res [migrate_exec_wrapper $src $k2 TYPE $k2]
+    assert_equal 2 [lindex $res 0]
+    assert_equal $t2 [lindex $res 1]
+    set res [migrate_exec_wrapper $src $k2 EXPIRE $k2 600]
+    assert_equal 2 [lindex $res 0]
+    set res [migrate_exec_wrapper $src $k2 TTL $k2]
+    assert_equal 2 [lindex $res 0]
+    assert {[lindex $res 1] > 0}
+    puts ">>> R&&W k2($t2, $k2) by wrapper when migrating k1: PASS"
+
+    # wait for the async migration to be finished
+    set new_size [expr {$bak_size - $total1}]
+    wait_for_condition 50 100 {
+        [get_slot_size $src $slot] == $new_size
+    } else {
+        fail "AsyncMigrate key($k1) is taking too much time!"
+    }
+    puts "AsyncMigrate key($k1){#$src => #$dst} finished."
+
+    # trigger the async migration of k2
+    trigger_async_migrate_key $src $dst $tag $maxbulks $maxbytes $k2
+
+    # read/write k1 by wrapper when migrating k2
+    set res [migrate_exec_wrapper $src $k1 TYPE $k1]
+    assert_match {*ERR*doesn't*exist*} $res
+    set res [migrate_exec_wrapper $src $k1 PERSIST $k1]
+    assert_match {*ERR*doesn't*exist*} $res
+    puts ">>> R&&W k1($t1, $k1) by wrapper when migrating k2: PASS"
+
+    # read/write k2 by wrapper when migrating k2
+    set res [migrate_exec_wrapper $src $k2 TYPE $k2]
+    assert_equal 2 [lindex $res 0]
+    assert_equal $t2 [lindex $res 1]
+    set res [migrate_exec_wrapper $src $k2 PERSIST $k2]
+    assert_match {*ERR*being*migrated*} $res
+    set res [migrate_exec_wrapper $src $k2 TTL $k2]
+    assert_equal 2 [lindex $res 0]
+    assert {[lindex $res 1] > 0}
+    puts ">>> R&&W k2($t2, $k2) by wrapper when migrating k2: PASS"
+
+    # wait for the async migration to be finished
+    wait_for_condition 50 100 {
+        [get_slot_size $src $slot] == 0
+    } else {
+        fail "AsyncMigrate key($k2) is taking too much time!"
+    }
+    puts "AsyncMigrate key($k2){#$src => #$dst} finished."
+
+    # check and remove the ttl on dst server
+    assert {[lindex [R $dst TTL $k2] 0] > 0}
+    assert_equal 1 [lindex [R $dst PERSIST $k2] 0]
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $bak_size [get_slot_size $dst $slot]
+    assert_equal $dig_src [R $dst debug digest]
+    assert_equal OK [R $dst slotscheck]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Verify the data after migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "Read&&Write a key by wrapper combine with slot async migrating" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    set slot 1
+    R $src debug populate 100 "{key:65}"
+    R $src debug populate 100 "{key:459}"
+    R $src debug populate 100 "{key:983}"
+    R $src debug populate 100 "{key:1017}"
+    R $src debug populate 100 "{key:3520}"
+    R $src debug populate 100 "{key:4243}"
+    R $src debug populate 100 "{key:5825}"
+    R $src debug populate 100 "{key:6528}"
+    R $src debug populate 100 "{key:7294}"
+    R $src debug populate 100 "{key:8468}"
+    set prefix "{2J8mrF}"
+    set strcnt 100;    # count of the string type keys
+    set cpxcnt 1;      # count of each complex type keys
+    set small 20;      # size of the small complex key
+    set large 100000;  # size of the large complex key
+    set total [create_some_pairs $src $prefix $strcnt $cpxcnt $small $large]
+    assert_equal OK [R $src slotscheck]
+    # record the digest and slot size brfore migration
+    set dig_src [R $src debug digest]
+    set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size): OK"
+
+    # random pick a key
+    set rand [expr {$total - ([randomInt 4] * 2 + 1)}]
+    set key "$prefix:$rand"
+    set type [lindex [get_key_type_size $src $key] 0]
+
+    # read/write the key by wrapper before migration
+    set res [migrate_exec_wrapper $src $key TYPE $key]
+    assert_equal 2 [lindex $res 0]
+    assert_equal $type [lindex $res 1]
+    set res [migrate_exec_wrapper $src $key EXPIRE $key 600]
+    assert_equal 2 [lindex $res 0]
+    set res [migrate_exec_wrapper $src $key TTL $key]
+    assert_equal 2 [lindex $res 0]
+    assert {[lindex $res 1] > 0}
+    puts ">>> R&&W key($type, $key) by wrapper before migration: PASS"
+
+    # trigger the async migration of slot_1
+    set tag 1;  # 0 => SLOTSMGRTSLOT-ASYNC, 1 => SLOTSMGRTTAGSLOT-ASYNC
+    set maxbulks 200;     # $small < $maxbulks < $large
+    set maxbytes 51200;   # 50KB(a small value, make the migration to be slower)
+    set numkeys 5000;     # should be much larger than the slot size
+    trigger_async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys
+
+    # read/write the key by wrapper when migrating
+    set res [migrate_exec_wrapper $src $key TYPE $key]
+    assert_equal 2 [lindex $res 0]
+    assert_equal $type [lindex $res 1]
+    set res [migrate_exec_wrapper $src $key PERSIST $key]
+    assert_match {*ERR*being*migrated*} $res
+    set res [migrate_exec_wrapper $src $key TTL $key]
+    assert_equal 2 [lindex $res 0]
+    assert {[lindex $res 1] > 0}
+    puts ">>> R&&W key($type, $key) by wrapper when migrating slot_1: PASS"
+
+    # wait for the async migration to be finished
+    wait_for_condition 50 100 {
+        [get_slot_size $src $slot] == 0
+    } else {
+        fail "AsyncMigrate is taking too much time!"
+    }
+    puts "AsyncMigrate slot_$slot{#$src => #$dst} finished."
+
+    # read/write the key by wrapper after migration
+    set res [migrate_exec_wrapper $src $key TYPE $key]
+    assert_match {*ERR*doesn't*exist*} $res
+    set res [migrate_exec_wrapper $src $key PERSIST $key]
+    assert_match {*ERR*doesn't*exist*} $res
+    set res [migrate_exec_wrapper $dst $key TTL $key]
+    assert_equal 2 [lindex $res 0]
+    assert {[lindex $res 1] > 0}
+    set res [migrate_exec_wrapper $dst $key PERSIST $key]
+    assert_equal 2 [lindex $res 0]
+    assert_equal 1 [lindex $res 1]
+    puts ">>> R&&W key($type, $key) by wrapper after migration: PASS"
+
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $bak_size [get_slot_size $dst $slot]
+    assert_equal $dig_src [R $dst debug digest]
+    assert_equal OK [R $dst slotscheck]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Verify the data after migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
diff --git a/extern/redis-5.0/tests/codis/tests/05-migration-failover.tcl b/extern/redis-5.0/tests/codis/tests/05-migration-failover.tcl
new file mode 100644
index 00000000..c3919444
--- /dev/null
+++ b/extern/redis-5.0/tests/codis/tests/05-migration-failover.tcl
@@ -0,0 +1,147 @@
+# Codis test for failover capabilities when migrating.
+
+source "../tests/includes/init-tests.tcl"
+
+test "The async migration can be continued after dst server switched" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 1; R $dst flushall;
+    set slot 1
+    R $src debug populate 100 "{key:65}"
+    R $src debug populate 100 "{key:459}"
+    R $src debug populate 100 "{key:983}"
+    R $src debug populate 100 "{key:1017}"
+    R $src debug populate 100 "{key:3520}"
+    R $src debug populate 100 "{key:4243}"
+    R $src debug populate 100 "{key:5825}"
+    R $src debug populate 100 "{key:6528}"
+    R $src debug populate 100 "{key:7294}"
+    R $src debug populate 100 "{key:8468}"
+    set prefix "{2J8mrF}"
+    set strcnt 100;    # count of the string type keys
+    set cpxcnt 1;      # count of each complex type keys
+    set small 20;      # size of the small complex key
+    set large 100000;  # size of the large complex key
+    set total [create_some_pairs $src $prefix $strcnt $cpxcnt $small $large]
+    assert_equal OK [R $src slotscheck]
+    # record the digest and slot size brfore migration
+    set dig_orig [R $src debug digest]
+    set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size): OK"
+
+    # trigger the async migration of slot_1
+    set tag 1;  # 0 => SLOTSMGRTSLOT-ASYNC, 1 => SLOTSMGRTTAGSLOT-ASYNC
+    set maxbulks 200;     # $small < $maxbulks < $large
+    set maxbytes 51200;   # 50KB(a small value, make the migration to be slower)
+    set numkeys 5000;     # should be much larger than the slot size
+    trigger_async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys
+
+    # trigger the master of destination group switching
+    kill_instance redis $dst
+    set dst [expr {$dst + $::group_count}]
+    wait_for_condition 1000 50 {
+        [RI $dst role] eq {master}
+    } else {
+        fail "The master of destination group switched failed!"
+    }
+    puts ">>> Wait for the master of destination group switched: PASS"
+
+    # trigger the async migration of slot_1 again to new dst server
+    trigger_async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys
+    wait_for_condition 50 100 {
+        [get_slot_size $src $slot] == 0
+    } else {
+        fail "AsyncMigrate is taking too much time!"
+    }
+    puts "AsyncMigrate slot_$slot{#$src => #$dst} finished."
+    puts ">>> Wait for the async migration to be finished: PASS"
+
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $bak_size [get_slot_size $dst $slot]
+    assert_equal $dig_orig [R $dst debug digest]
+    assert_equal OK [R $dst slotscheck]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Verify the data after failover && migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
+
+test "The async migration can be continued after src server switched" {
+    # init the env
+    puts "Starting..."
+    set src 0; R $src flushall;
+    set dst 2; R $dst flushall;
+    set slot 1
+    R $src debug populate 100 "{key:65}"
+    R $src debug populate 100 "{key:459}"
+    R $src debug populate 100 "{key:983}"
+    R $src debug populate 100 "{key:1017}"
+    R $src debug populate 100 "{key:3520}"
+    R $src debug populate 100 "{key:4243}"
+    R $src debug populate 100 "{key:5825}"
+    R $src debug populate 100 "{key:6528}"
+    R $src debug populate 100 "{key:7294}"
+    R $src debug populate 100 "{key:8468}"
+    set prefix "{2J8mrF}"
+    set strcnt 100;    # count of the string type keys
+    set cpxcnt 1;      # count of each complex type keys
+    set small 20;      # size of the small complex key
+    set large 100000;  # size of the large complex key
+    set total [create_some_pairs $src $prefix $strcnt $cpxcnt $small $large]
+    assert_equal OK [R $src slotscheck]
+    # record the digest and slot size brfore migration
+    set dig_orig [R $src debug digest]
+    set bak_size [get_slot_size $src $slot]
+    puts ">>> Init the enviroment(slot=$slot,size=$bak_size): OK"
+
+    # restart the replica instance of the src master(The data on the src master
+    # which genreated by DEBUG POPULATE command can't propagate to its replica,
+    # so we should restart the replica, trigger a full resynchronization, after
+    # that, the data on the replica will be the same with the src master.)
+    set sreplica [expr {$src + $::group_count}]
+    kill_instance redis $sreplica
+    restart_instance redis $sreplica
+    wait_for_condition 1000 50 {
+        [RI $sreplica master_link_status] eq {up}
+    } else {
+        fail "Replica(#$sreplica) is unable to sync with the src master(#$src)"
+    }
+    assert_equal $bak_size [get_slot_size $sreplica $slot]
+    assert_equal OK [R $sreplica slotscheck]
+    puts ">>> Restart the replica of src master and wait it up: PASS"
+
+    # trigger the async migration of slot_1
+    set tag 1;  # 0 => SLOTSMGRTSLOT-ASYNC, 1 => SLOTSMGRTTAGSLOT-ASYNC
+    set maxbulks 200;     # $small < $maxbulks < $large
+    set maxbytes 51200;   # 50KB(a small value, make the migration to be slower)
+    set numkeys 5000;     # should be much larger than the slot size
+    trigger_async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys
+
+    # trigger the master of source group switching
+    kill_instance redis $src
+    set src $sreplica
+    wait_for_condition 1000 50 {
+        [RI $src role] eq {master}
+    } else {
+        fail "The master of source group switched failed!"
+    }
+    puts ">>> Wait for the master of source group switched: PASS"
+
+    # trigger the async migration of slot_1 again from new src server
+    trigger_async_migrate_slot $src $dst $tag $maxbulks $maxbytes $slot $numkeys
+    wait_for_condition 50 100 {
+        [get_slot_size $src $slot] == 0
+    } else {
+        fail "AsyncMigrate is taking too much time!"
+    }
+    puts "AsyncMigrate slot_$slot{#$src => #$dst} finished."
+    puts ">>> Wait for the async migration to be finished: PASS"
+
+    # verify the data isn't corrupted or changed after migration
+    assert_equal $bak_size [get_slot_size $dst $slot]
+    assert_equal $dig_orig [R $dst debug digest]
+    assert_equal OK [R $dst slotscheck]
+    assert_equal OK [R $src slotscheck]
+    puts ">>> Verify the data after failover && migration: PASS"
+    puts -nonewline ">>> End of the case: "
+}
diff --git a/extern/redis-5.0/tests/codis/tests/includes/init-tests.tcl b/extern/redis-5.0/tests/codis/tests/includes/init-tests.tcl
index dd2645cc..6551b01e 100644
--- a/extern/redis-5.0/tests/codis/tests/includes/init-tests.tcl
+++ b/extern/redis-5.0/tests/codis/tests/includes/init-tests.tcl
@@ -1,7 +1,13 @@
 # Initialization tests -- most units will start including this.
 
+set debug_print 0
+
+proc group_ms_name {gid} {
+    return "codis-ut-$gid"
+}
+
 test "(init) Restart killed instances" {
-    foreach type {redis} {
+    foreach type {redis sentinel} {
         foreach_${type}_id id {
             if {[get_instance_attrib $type $id pid] == -1} {
                 puts -nonewline "$type/$id "
@@ -12,47 +18,162 @@ test "(init) Restart killed instances" {
     }
 }
 
+proc get_ping_reply {type id} {
+    if {[string compare $type "redis"] == 0} {
+        R $id ping
+    } else {
+        S $id ping
+    }
+}
+
 test "(init) All instances are reachable" {
-    foreach_redis_id id {
-        # Every node should be reachable.
-        wait_for_condition 1000 50 {
-            ([catch {R $id ping} ping_reply] == 0) &&
-            ($ping_reply eq {PONG})
-        } else {
-            catch {R $id ping} err
-            fail "Node #$id keeps replying '$err' to PING."
+    if {$debug_print == 1} {
+        puts "Starting..."
+    }
+
+    foreach type {redis sentinel} {
+        foreach_${type}_id id {
+            # Every redis node should be reachable.
+            wait_for_condition 1000 50 {
+                ([catch {get_ping_reply $type $id} ping_reply] == 0) &&
+                ($ping_reply eq {PONG})
+            } else {
+                catch {get_ping_reply $type $id} err
+                fail "Node $type#$id keeps replying '$err' to PING."
+            }
+            if {$debug_print == 1} {
+                puts "Node $type#$id reply '$ping_reply' to PING."
+            }
         }
     }
 }
 
-test "(init) Flush old data and reset the server role" {
-    set group_count [expr {[llength $::redis_instances]/2}]
+test "(init) Remove old master entries from sentinels" {
+    for {set gid 1} {$gid <= $::group_count} {incr gid} {
+        foreach_sentinel_id id {
+            catch {S $id SENTINEL REMOVE [group_ms_name $gid]}
+        }
+    }
+}
+
+test "(init) Flush old data and reset the role of redis instances" {
+    if {$debug_print == 1} {
+        puts "Starting..."
+    }
+
     foreach_redis_id id {
-        if {$id < $group_count} {
+        if {$id < $::group_count} {
             # Master instance
             R $id replicaof no one
             R $id flushall
         } else {
             # Replica instance
-            set ms_id [expr {$id - $group_count}]
-            set ms_host [get_instance_attrib redis $ms_id host]
-            set ms_port [get_instance_attrib redis $ms_id port]
-            R $id replicaof $ms_host $ms_port
+            set ms_id [expr {$id - $::group_count}]
+            R $id replicaof [get_instance_attrib redis $ms_id host] \
+                [get_instance_attrib redis $ms_id port]
         }
     }
 
     # Wait for all the replicas to sync
-    set max_retry 1000
+    set max_retry 1000;  # for 1st replica instance
     foreach_redis_id id {
-        if {$id < $group_count} {
-            continue
-        } elseif {$id > $group_count} {
-            set max_retry 3
+        if {$id < $::group_count} {
+            continue;         # skip all the master instances
+        } elseif {$id > $::group_count} {
+            set max_retry 3;  # for 2nd,3rd,4th... replica instances
         }
+
         wait_for_condition $max_retry 50 {
             [RI $id master_link_status] eq {up}
         } else {
-            fail "Unable to init the server role."
+            fail "Unable to init the role of redis#$id."
+        }
+        if {$debug_print == 1} {
+            puts "Replica redis#$id is synced with its master."
+        }
+    }
+}
+
+test "(init) Sentinels can start monitoring all master instances" {
+    set quorum [expr {$::sentinel_count/2+1}]
+    for {set gid 1} {$gid <= $::group_count} {incr gid} {
+        set ms_id [expr {$gid - 1}]
+        set name [group_ms_name $gid]
+        foreach_sentinel_id id {
+            S $id SENTINEL MONITOR $name \
+                [get_instance_attrib redis $ms_id host] \
+                [get_instance_attrib redis $ms_id port] $quorum
+        }
+        foreach_sentinel_id id {
+            assert {[S $id sentinel master $name] ne {}}
+            S $id SENTINEL SET $name down-after-milliseconds 2000
+            S $id SENTINEL SET $name failover-timeout 20000
+            S $id SENTINEL SET $name parallel-syncs 10
+        }
+    }
+}
+
+test "(init) Sentinels can talk with all master instances" {
+    if {$debug_print == 1} {
+        puts "Starting..."
+    }
+
+    for {set gid 1} {$gid <= $::group_count} {incr gid} {
+        set name [group_ms_name $gid]
+        foreach_sentinel_id id {
+            wait_for_condition 1000 50 {
+                [catch {S $id SENTINEL GET-MASTER-ADDR-BY-NAME $name}] == 0
+            } else {
+                fail "Sentinel#$id can't talk with the master($name)."
+            }
+        }
+        if {$debug_print == 1} {
+            puts "All sentinels can talk with the master($name)."
+        }
+    }
+}
+
+proc ms_info_item {id name item} {
+    dict get [S $id SENTINEL MASTER $name] $item
+}
+
+test "(init) Sentinels are able to auto-discover other sentinels" {
+    if {$debug_print == 1} {
+        puts "Starting..."
+    }
+
+    set other_count [expr {$::sentinel_count - 1}]
+    for {set gid 1} {$gid <= $::group_count} {incr gid} {
+        set name [group_ms_name $gid]
+        foreach_sentinel_id id {
+            wait_for_condition 1000 50 {
+                [ms_info_item $id $name "num-other-sentinels"] == $other_count
+            } else {
+                fail "At least some sentinel can't detect some other sentinel"
+            }
+        }
+        if {$debug_print == 1} {
+            puts "All sentinels can detect others for master($name)."
+        }
+    }
+}
+
+test "(init) Sentinels are able to auto-discover slaves" {
+    if {$debug_print == 1} {
+        puts "Starting..."
+    }
+
+    for {set gid 1} {$gid <= $::group_count} {incr gid} {
+        set name [group_ms_name $gid]
+        foreach_sentinel_id id {
+            wait_for_condition 1000 50 {
+                [ms_info_item $id $name "num-slaves"] == 1
+            } else {
+                fail "At least some sentinel can't detect some slave"
+            }
+        }
+        if {$debug_print == 1} {
+            puts "All sentinels can detect all slaves for master($name)."
         }
     }
 }
